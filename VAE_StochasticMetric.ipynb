{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce546596",
      "metadata": {
        "id": "ce546596"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Special file just for the improved variance estimate for VAEs as presented in\n",
        "# 2018 G. Arvanitidis \"Latent Space Oddity: on the Curvature of Deep Generative\n",
        "# Models\" (https://arxiv.org/abs/1710.11379)\n",
        "# ------------------------------------------------------------------------------\n",
        "import torch\n",
        "import torch as pt\n",
        "import numpy as np\n",
        "use_cuda = torch.cuda.is_available()\n",
        "gpu_indx  = 0\n",
        "device = torch.device(gpu_indx if use_cuda else \"cpu\")\n",
        "\n",
        "class RBF (pt.nn.Module):\n",
        "    \"\"\"\n",
        "    Class to improve the variance of VAE\n",
        "    \"\"\"\n",
        "    def __init__(self, centers, bandwidth, X_dim, zeta=1e-1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.k = centers.shape[0]\n",
        "        self.centers = pt.nn.Parameter(pt.Tensor(centers), requires_grad=False)\n",
        "        self.bandwidth = pt.nn.Parameter(pt.Tensor(bandwidth), requires_grad=False)\n",
        "\n",
        "        self.W = pt.nn.Linear(centers.shape[0], X_dim, bias=False)\n",
        "        self.zeta = pt.nn.Parameter(pt.Tensor([zeta]), requires_grad=False)\n",
        "\n",
        "\n",
        "    def forward(self, z_input):\n",
        "        N = z_input.shape[0]\n",
        "        latent_dim = z_input.shape[1]\n",
        "\n",
        "        v = pt.exp(-self.bandwidth * pt.sum(\n",
        "                (z_input.view(N, 1, latent_dim) - self.centers.view(1, self.k, latent_dim))**2,\n",
        "                axis=-1\n",
        "                )\n",
        "            )\n",
        "        beta = self.W(v) + self.zeta\n",
        "\n",
        "        return beta\n",
        "\n",
        "\n",
        "def trainRBF (modelE, modelD, dataloader, latent_dim, X_dim, k, zeta=1e-3, curveMetric=1, max_epochs=100, batch_size=16):\n",
        "    \"\"\"\n",
        "    Using trained VAE we now fit more accurate variance estimates using a RBF network.\n",
        "\n",
        "    Arguments:\n",
        "        modelE (torch.nn.Module) : Encoder of VAE.\n",
        "        modelD (torch.nn.Module) : Decoder of VAE.\n",
        "        dataloader (torch.nn.DataLoader) : training data used for VAE.\n",
        "        latent_dim (int) : dimension of latent space.\n",
        "        X_dim (np.ndarray) [C, H, W] : shape of input/output space.\n",
        "        k (int) : number of clusters for k-means.\n",
        "        zeta (float) : minimal precision (zeta > 0, at 0 the variance goes to infinity)\n",
        "        curveMetric (float) : RBF bandwidth parameter, higher values create smoother variances, lower values make the RBF stick closer to the data (less smooth)\n",
        "        max_epochs (int) : training of RBF\n",
        "\n",
        "    Returns:\n",
        "        Trained RBF (torch.nn.Module)\n",
        "    \"\"\"\n",
        "    N = len(dataloader.dataset)\n",
        "    # Keep a copy of the X_dim\n",
        "    input_dim = X_dim\n",
        "    device = next(modelD.parameters()).device\n",
        "    modelE.eval(), modelD.eval()\n",
        "\n",
        "    ### Compute embedded vectors\n",
        "    with pt.no_grad():\n",
        "        z_input = []\n",
        "        kl_loss = []\n",
        "        for X_input, _ in dataloader:\n",
        "            X_input = X_input.to(device)\n",
        "            zmean, zlogvar = modelE(X_input)\n",
        "            z_input.append(zmean.detach().cpu().numpy())\n",
        "            kl_loss.append((-0.5 * (1 + zlogvar - zmean**2 - zlogvar.exp()).sum(dim=1)).detach())\n",
        "\n",
        "        z_input = np.concatenate(z_input, axis=0)\n",
        "        kl_loss = pt.cat(kl_loss, dim=0).mean()\n",
        "\n",
        "    ### Initialize the centers randomly between zmin and zmax with margin 1\n",
        "    z_min = np.min(z_input.T, axis=1) - 1\n",
        "    z_max = np.max(z_input.T, axis=1) + 1\n",
        "    centers = np.random.uniform(z_min, z_max, size=[k, latent_dim])\n",
        "\n",
        "    ### Generate the sets that belong to the same center, S shape [N]\n",
        "    # These shaped subtractions:\n",
        "    # [N, 1, latent_dim] - [1, k, latent_dim] -> [N, k, latent_dim]\n",
        "    # S contains the index of which set each point belongs to\n",
        "    Sidx = np.argmin(np.sum((z_input.reshape(N, 1, latent_dim) - centers.reshape(1, k, latent_dim))**2, axis=-1), axis=-1)\n",
        "\n",
        "    ### Repeat center assignment until S_idx does not change anymore\n",
        "    print(\"Starting k-means: \")\n",
        "    iterc = 0\n",
        "    while (True):\n",
        "        iterc+=1\n",
        "        if (iterc % 10 == 0):\n",
        "            print(f\"Iteration {iterc}\")\n",
        "\n",
        "        for i in range(k):\n",
        "            S_i = z_input[Sidx==i]\n",
        "            if S_i.shape[0] == 0:\n",
        "                # We don't want empty centers, randomize until we find non-empty\n",
        "                centers[i] = np.random.uniform(z_min, z_max, size=latent_dim)\n",
        "            else:\n",
        "                centers[i] = np.sum(S_i, axis=0) / S_i.shape[0]\n",
        "\n",
        "        Sidx_new = np.argmin(np.sum((z_input.reshape(N, 1, latent_dim) - centers.reshape(1, k, latent_dim))**2, axis=-1), axis=-1)\n",
        "\n",
        "        if (Sidx == Sidx_new).all():\n",
        "            break\n",
        "        else:\n",
        "            Sidx = Sidx_new\n",
        "\n",
        "    S_shapes = []\n",
        "    for i in range(k):\n",
        "        S_i = z_input[Sidx==i]\n",
        "        S_shapes.append(S_i.shape[0])\n",
        "\n",
        "    # print(f\"Number of points within each center_set: {S_shapes}\")\n",
        "\n",
        "    bandwidth = np.ones(k)\n",
        "\n",
        "    for i in range(k):\n",
        "        S_i = z_input[Sidx==i]\n",
        "        if S_i.shape[0] == 0:\n",
        "            # If there are no points in this center, it should have minimal influence\n",
        "            bandwidth[i] = 1e-3\n",
        "        else:\n",
        "            # Prevent that all S_i are exactly on the center\n",
        "            eps = 1e-6\n",
        "            bandwidth[i] = 0.5 * ( curveMetric / S_i.shape[0] * np.sum(np.sqrt(np.sum((S_i - centers[i])**2, axis=-1))+eps) )**-2\n",
        "\n",
        "    print(\"Training RBF...\")\n",
        "    ### Start building network and clipper\n",
        "    class PosClipper (object):\n",
        "        def __call__(self, module):\n",
        "            if hasattr(module, 'weight'):\n",
        "                w = module.weight.data\n",
        "                w.clamp_(0)\n",
        "\n",
        "    if not isinstance(X_dim, int) and len(X_dim) > 1:\n",
        "        # Not a scalar value\n",
        "        input_dim = np.asarray(input_dim).prod()\n",
        "\n",
        "    rbfNN = RBF(centers, bandwidth, input_dim, zeta)\n",
        "    rbfNN.to(device)\n",
        "    clipper = PosClipper()\n",
        "\n",
        "    optimizerRBF = pt.optim.Adam(\n",
        "                    rbfNN.parameters(),\n",
        "                    lr=0.01,\n",
        "                    weight_decay=1e-4\n",
        "                )\n",
        "\n",
        "    rbfNN.train()\n",
        "    rbfNN.apply(clipper)\n",
        "    for epoch in range(max_epochs):\n",
        "        epoch_loss = 0\n",
        "        shuffledIdx = pt.randperm(N)\n",
        "\n",
        "        for i in range(0, N, batch_size):\n",
        "            with pt.set_grad_enabled(True):\n",
        "                modelD.eval()\n",
        "                rbfNN.zero_grad()\n",
        "                idx = shuffledIdx[i:i+batch_size]\n",
        "                z = pt.Tensor(z_input[idx]).to(device)\n",
        "                X = dataloader.dataset.data[idx].to(device)\n",
        "\n",
        "                rbfVar = 1 / rbfNN(z)\n",
        "                Xmean, Xlogvar = modelD(z)\n",
        "                if not isinstance(X_dim, (int, np.int32, np.int64)) and len(X_dim) > 1:\n",
        "                    Xmean = Xmean.view(-1, input_dim)\n",
        "                    X = X.view(-1, input_dim)\n",
        "                rec_loss = 0.5 * pt.log(rbfVar).sum(dim=1) + 0.5 * ((X - Xmean)**2 / rbfVar).sum(dim=1)\n",
        "                rec_loss += (input_dim/2) * np.log(2*np.pi)\n",
        "\n",
        "                loss = rec_loss.sum()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizerRBF.step()\n",
        "            rbfNN.apply(clipper)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        epoch_loss /= N\n",
        "        # Add this constant value so it's the complete ELBO loss\n",
        "        epoch_loss += kl_loss\n",
        "\n",
        "        if (epoch % 10 == 0):\n",
        "            print(f\"Epoch [{epoch+1}/{max_epochs}]: Loss {epoch_loss:.4f}\")\n",
        "\n",
        "    rbfNN.eval()\n",
        "    return rbfNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9965f67",
      "metadata": {
        "id": "e9965f67"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "\n",
        "class MNIST(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Loads n amount of training data of specified classes from one of the MNIST datasets (Digits, Fashion, Kuzushiji, EMNIST). MNIST data has shape [-1, 1, 28, 28].\n",
        "\n",
        "    Arguments:\n",
        "        dataset (torchvision.datasets) : one of the MNIST datasets transformed with ToTensor.\n",
        "        labels (List): an integer list containing all the classes you want to have in the data.\n",
        "        number_of_samples (int): how many of each class should appear.\n",
        "        train (boolean): should it be training or testing dataset\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, labels, number_of_samples=1000, train=True):\n",
        "        super().__init__()\n",
        "        self.data = []\n",
        "        self.targets = []\n",
        "\n",
        "        for label in labels:\n",
        "            idx = (dataset.targets == label)\n",
        "            if (idx.shape[0] == 0):\n",
        "                print(f\"ERROR: Label {label} not found!\")\n",
        "                continue\n",
        "\n",
        "            # Originally data are bytes, we want floats between -1 and 1\n",
        "            self.data.append(2*(dataset.data[idx][:number_of_samples].float() / 255)-1)\n",
        "            self.targets.append(dataset.targets[idx][:number_of_samples])\n",
        "\n",
        "        self.data = torch.cat(self.data, dim=0).view(-1, 1, 28, 28)\n",
        "        # Typecast targets as longs.\n",
        "        self.targets = torch.cat(self.targets, dim=0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.data[idx], self.targets[idx])\n",
        "\n",
        "class MNISTDigits (MNIST):\n",
        "    \"\"\"\n",
        "    Loads n amount of training data of specified MNIST digits.\n",
        "\n",
        "    Arguments:\n",
        "        digits (List): an integer list containing all the digits you want to have in the data.\n",
        "        number_of_samples (int): how many of each digit should appear.\n",
        "        train (boolean): should it be training or testing dataset\n",
        "    \"\"\"\n",
        "    def __init__(self, digits, number_of_samples=1000, train=True):\n",
        "        dataset = torchvision.datasets.MNIST(\"Data/\", train=train, download=True)\n",
        "\n",
        "        super().__init__(dataset, digits, number_of_samples, train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f536c194",
      "metadata": {
        "id": "f536c194"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "\n",
        "class BlackImagesDataset(Dataset):\n",
        "    def __init__(self, num_images, image_size, label):\n",
        "        self.num_images = num_images\n",
        "        self.image_size = image_size\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_images\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = torch.zeros(self.image_size, dtype=torch.float32)\n",
        "        label = self.label\n",
        "        return image, label\n",
        "\n",
        "class WhiteImagesDataset(Dataset):\n",
        "    def __init__(self, num_images, image_size, label):\n",
        "        self.num_images = num_images\n",
        "        self.image_size = image_size\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_images\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = torch.ones(self.image_size, dtype=torch.float32)\n",
        "        label = self.label\n",
        "        return image, label\n",
        "\n",
        "def prepare_datasets(num_black_images=50):\n",
        "    # Load MNIST dataset\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    # Create dataset of black images (label 10 for black images)\n",
        "    black_train_dataset = BlackImagesDataset(num_black_images, (1, 28, 28), 10)\n",
        "    black_test_dataset = BlackImagesDataset(num_black_images, (1, 28, 28), 10)\n",
        "\n",
        "    white_train_dataset = WhiteImagesDataset(num_black_images, (1, 28, 28), 11)\n",
        "    white_test_dataset = WhiteImagesDataset(num_black_images, (1, 28, 28), 11)\n",
        "\n",
        "    # Concatenate MNIST with black images dataset\n",
        "    train_dataset = ConcatDataset([train_dataset, black_train_dataset, white_train_dataset])\n",
        "    test_dataset = ConcatDataset([test_dataset, black_test_dataset, white_test_dataset])\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset, test_dataset = prepare_datasets()\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "# Now you can use train_loader and test_loader for training and testing your VAE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9942833",
      "metadata": {
        "id": "f9942833"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(test_loader)\n",
        "test_images, test_labels = next(dataiter)\n",
        "test_images[0]\n",
        "train_iter = iter(train_loader)\n",
        "train_images, train_labels = next(train_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S5F93giYdF7m",
      "metadata": {
        "id": "S5F93giYdF7m"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# PyTorch implementation of a convolutional Variational Autoencoder (2014 D.\n",
        "# Kingma \"Auto-Encoding Variational Bayes\" in https://arxiv.org/abs/1312.6114)\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch as pt\n",
        "\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "\n",
        "class ConvBlock (nn.Sequential):\n",
        "    def __init__ (self, in_c, out_c, kernel_size, stride=1):\n",
        "        super().__init__()\n",
        "        self.add_module('Convolution', nn.utils.spectral_norm(nn.Conv2d(in_c, out_c, kernel_size, stride)))\n",
        "        self.add_module('BatchNorm', nn.BatchNorm2d(out_c, affine=True))\n",
        "        self.add_module('Activation', nn.ELU())\n",
        "\n",
        "class ConvTransposeBlock (nn.Sequential):\n",
        "    def __init__ (self, in_c, out_c, kernel_size, stride=1):\n",
        "        super().__init__()\n",
        "        self.add_module('ConvTranspose', nn.utils.spectral_norm(nn.ConvTranspose2d(in_c, out_c, kernel_size, stride)))\n",
        "        self.add_module('BatchNorm', nn.BatchNorm2d(out_c, affine=True))\n",
        "        self.add_module('Activation', nn.ELU())\n",
        "\n",
        "\n",
        "class Encoder (nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder of 2D VAE, producing latent multivariate normal distributions from input images. We return logarithmic variances as they have the real numbers as domain.\n",
        "\n",
        "    Forward pass:\n",
        "        1 Input:\n",
        "            i)  Image of shape [N, C, H, W] (by default 1x28x28 MNIST images)\n",
        "        2 Outputs:\n",
        "            i)  Means of latent distributions of shape [N, latent_dim]\n",
        "            ii) Logarithmic variances of latent distribution of shape [N, latent_dim] (Approximation of multivariate Gaussian, covariance is strictly diagonal, i.e. [N, d, d] is now [N, d])\n",
        "\n",
        "    Arguments:\n",
        "        X_dim (list) : dimensions of input 2D image, in the form of [Channels, Height, Width]\n",
        "        latent_dim (int) : dimension of latent space.\n",
        "    \"\"\"\n",
        "    def __init__(self, X_dim=[1,28,28], latent_dim=16):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        conv1_outchannels = 32\n",
        "        conv2_outchannels = 32\n",
        "\n",
        "        # How the convolutions change the shape\n",
        "        conv_outputshape = (\n",
        "            conv2_outchannels\n",
        "            * int(((X_dim[1]-4)/2 - 2)/2 + 1)\n",
        "            * int(((X_dim[2]-4)/2 - 2)/2 + 1)\n",
        "        )\n",
        "\n",
        "        self.enc = nn.Sequential(\n",
        "            ConvBlock(X_dim[0], conv1_outchannels, kernel_size=4, stride=2),\n",
        "            ConvBlock(conv1_outchannels, conv2_outchannels, kernel_size=3, stride=2)\n",
        "        )\n",
        "\n",
        "        self.zmean = nn.Linear(conv_outputshape, latent_dim)\n",
        "        self.zlogvar = nn.Linear(conv_outputshape, latent_dim)\n",
        "\n",
        "\n",
        "    def forward (self, X):\n",
        "        x = self.enc(X)\n",
        "        x = x.view(X.shape[0], -1)\n",
        "        mean = self.zmean(x)\n",
        "        logvar = self.zlogvar(x)\n",
        "\n",
        "        return mean, logvar\n",
        "\n",
        "\n",
        "class Decoder (nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder of 2D VAE, producing output multivariate normal distributions from latent vectors. We return logarithmic variances as they have the real numbers as domain.\n",
        "\n",
        "    Forward pass:\n",
        "        1 Input:\n",
        "            i)  Latent vector of shape [N, latent_dim]\n",
        "        2 Outputs:\n",
        "            i)  Means of output distributions of shape [N, C, H, W]\n",
        "            ii) Variances of output distribution of shape [N, C, H, W] (Approximation of multivariate Gaussian, covariance is strictly diagonal). We assume constant variance during VAE training.\n",
        "\n",
        "    Arguments:\n",
        "        X_dim (list) : dimensions of input 2D image, in the form of [Channels, Height, Width]\n",
        "        latent_dim (int) : dimension of latent space.\n",
        "    \"\"\"\n",
        "    def __init__(self, X_dim=[1,28,28], latent_dim=16):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        # Currently number of clusters is set to 4*latent_dim as a good rule of thumb, can be changed, but then also change it later during training!\n",
        "        self.improved_variance = True\n",
        "        k = 4*latent_dim\n",
        "        self.rbfNN = RBF(centers=pt.zeros(k,latent_dim), bandwidth=pt.zeros(k), X_dim=np.prod(X_dim))\n",
        "\n",
        "        conv1_outchannels = 32\n",
        "        conv2_outchannels = 32\n",
        "\n",
        "        # How the convolutions change the shape\n",
        "        self.conv_outputshape = (\n",
        "            int(((X_dim[1]-4)/2 - 2)/2 + 1),\n",
        "            int(((X_dim[2]-4)/2 - 2)/2 + 1)\n",
        "        )\n",
        "\n",
        "        self.lin = nn.Linear(latent_dim, conv2_outchannels*self.conv_outputshape[0]*self.conv_outputshape[1])\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            ConvTransposeBlock(conv2_outchannels, conv1_outchannels, kernel_size=3, stride=2),\n",
        "            ConvTransposeBlock(conv1_outchannels, 32, kernel_size=4, stride=2)\n",
        "        )\n",
        "\n",
        "        self.Xmean = nn.Sequential(\n",
        "            nn.Conv2d(32, X_dim[0], kernel_size=1),\n",
        "            # Output is grayscale between -1 and 1\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward (self, z):\n",
        "        \"\"\"\n",
        "        When improved_variance is set to True, we use a trained RBF to return a better variance estimate as described in \"Arvanitidis et al. (2018): Latent Space Oddity\". Of course the RBF has to be assigned to the Decoder first.\n",
        "        \"\"\"\n",
        "        x = self.lin(z)\n",
        "        x = x.view(z.shape[0], -1, self.conv_outputshape[0], self.conv_outputshape[1])\n",
        "        x = self.conv(x)\n",
        "        mean = self.Xmean(x)\n",
        "\n",
        "        if not self.improved_variance:\n",
        "            # We freeze the variance as constant 0.5. Requires grad so metric computation goes smoothly (i.e. returns no gradient)\n",
        "            var = pt.ones_like(mean, requires_grad=True) * 0.5\n",
        "        else:\n",
        "            var = 1/self.rbfNN(z)\n",
        "\n",
        "        return mean, var\n",
        "\n",
        "\n",
        "def train (dataloader, modelE, modelD, latent_dim=2, lr=5e-3, max_epochs=100, device=None):\n",
        "    \"\"\"\n",
        "    Trains the VAE on data presented in dataloader for max_epochs. By default trained using Adam optimizer with learning rate 5e-3 and weight decay 1e-4, and having a multiplicative learning rate scheduler (0.95 multiplier per epoch).\n",
        "\n",
        "    Arguments:\n",
        "        dataloader (nn.utils.data.Dataloader) : 2D images of shape [N, C, H, W]\n",
        "            loaded in batches of N. Unsupervised, so no targets/labels needed.\n",
        "        latent_dim (int) : latent dimension of autoencoder.\n",
        "\n",
        "    Returns:\n",
        "        modelE (Encoder: nn.Module) : trained encoder architecture.\n",
        "        modelD (Decoder: nn.Module) : trained decoder architecture.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(\"Outputs\"):\n",
        "        os.makedirs(\"Outputs\")\n",
        "    if not os.path.exists(\"TrainedModels\"):\n",
        "        os.makedirs(\"TrainedModels\")\n",
        "\n",
        "    if device is None:\n",
        "        device = pt.device('cuda') if pt.cuda.is_available() else pt.device('cpu')\n",
        "\n",
        "    X_dim = dataloader.dataset[0][0].shape\n",
        "\n",
        "    ### Initialize encoder, decoder and optimizers\n",
        "    modelE = modelE\n",
        "    modelD = modelD\n",
        "    modelE.train(), modelD.train()\n",
        "    modelD.improved_variance = False    # During training of VAE no RBF\n",
        "\n",
        "    # Show the network architectures\n",
        "    summary(modelE, X_dim)\n",
        "    summary(modelD, (latent_dim,))\n",
        "\n",
        "    optimizer = pt.optim.Adam(\n",
        "                list(modelE.parameters())+list(modelD.parameters()),\n",
        "                lr=lr,\n",
        "                weight_decay=1e-4\n",
        "            )\n",
        "\n",
        "    scheduler = pt.optim.lr_scheduler.MultiplicativeLR(optimizer, lambda epoch: 0.95)\n",
        "\n",
        "\n",
        "    ### Loop over epochs\n",
        "    loss_history = []\n",
        "    for epoch in range(max_epochs):\n",
        "        ### Store an evaluation output in every epoch\n",
        "        with pt.set_grad_enabled(False):\n",
        "            randidx = np.random.randint(len(dataloader.dataset))\n",
        "            output = modelD(\n",
        "                modelE(\n",
        "                    dataloader.dataset[randidx][0].to(device).unsqueeze(dim=0)\n",
        "                )[0]\n",
        "            )[0].detach().cpu().squeeze().numpy()\n",
        "\n",
        "        fig = plt.figure(figsize=(12, 12))\n",
        "        # Image from [-1,1] to [0,1]\n",
        "        plt.imshow((output+1)/2, cmap='gray')\n",
        "        plt.savefig(f\"Outputs/train_{epoch+1: 04d}.png\")\n",
        "        plt.close(fig)\n",
        "\n",
        "\n",
        "        L = 4\n",
        "        epoch_loss = 0\n",
        "        for X_input in dataloader:\n",
        "            with pt.set_grad_enabled(True):\n",
        "                # No need for targets/labels\n",
        "                X_input = X_input[0].to(device)\n",
        "                modelE.zero_grad(), modelD.zero_grad()\n",
        "\n",
        "                zmean, zlogvar = modelE(X_input)\n",
        "                kl_loss = -0.5 * (1 + zlogvar - zmean**2 - zlogvar.exp()).sum(dim=1)\n",
        "\n",
        "                rec_loss = 0.0\n",
        "                for _ in range(L):\n",
        "                    # Reparametrization trick\n",
        "                    xi = pt.normal(pt.zeros_like(zmean))\n",
        "                    z = zmean + pt.exp(zlogvar/2) * xi\n",
        "\n",
        "                    Xmean, Xlogvar = modelD(z)\n",
        "                    # rec_loss as the negative log likelihood. Constant log(2pi^k/2) keeps loss positive, but is optional.\n",
        "                    rec_loss += 0.5 * Xlogvar.sum(dim=[1,2,3]) + 0.5 * ((X_input - Xmean)**2 / Xlogvar.exp()).sum(dim=[1,2,3])\n",
        "                    rec_loss += (np.prod(X_input.shape[1:])/2) * np.log(6.283)\n",
        "                rec_loss /= L\n",
        "\n",
        "                loss = (kl_loss + rec_loss).mean()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Length of dataloader is the amount of batches, not the total number of data points\n",
        "        epoch_loss /= len(dataloader.dataset)\n",
        "        loss_history.append(epoch_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{max_epochs}]: Loss {epoch_loss:.4e}\")\n",
        "\n",
        "\n",
        "        ### See how the loss evolves\n",
        "        fig = plt.figure(figsize=(12,9))\n",
        "        plt.plot(loss_history, label='Loss History')\n",
        "\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlim(0, epoch+1)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        fig.savefig(\"Outputs/LossHistory.png\", bbox_inches='tight')\n",
        "        plt.close(fig)\n",
        "\n",
        "        pt.save(modelE.state_dict(), \"TrainedModels/trainedVAE_E.pth\")\n",
        "        pt.save(modelD.state_dict(), \"TrainedModels/trainedVAE_D.pth\")\n",
        "\n",
        "\n",
        "    ### After training has finished, create better variance estimate with RBF\n",
        "    # Currently parameters are just set with default values, work well in general setting.\n",
        "    rbfNN = trainRBF(modelE, modelD, dataloader, latent_dim, X_dim, k=4*latent_dim, zeta=1e-2, curveMetric=1, max_epochs=50, batch_size=dataloader.batch_size)\n",
        "    # Set the better estimate in the decoder\n",
        "    modelD.rbfNN = rbfNN\n",
        "    modelD.improved_variance = True\n",
        "\n",
        "    pt.save(modelD.state_dict(), \"TrainedModels/trainedVAE_D.pth\")\n",
        "\n",
        "    return modelE, modelD\n",
        "\n",
        "\n",
        "\n",
        "print(\"Starting VAE training on MNIST data...\")\n",
        "latent_dim = 40\n",
        "#dataset = MNISTDigits(\n",
        "#    list(range(10)),\n",
        "#    number_of_samples=20000,\n",
        "#    train=True\n",
        "#)\n",
        "#data_loader = pt.utils.data.DataLoader(\n",
        "#    dataset,\n",
        "#    batch_size=128,\n",
        "#    shuffle=True,\n",
        "#    num_workers=1,\n",
        "#    pin_memory=True\n",
        "#)\n",
        "\n",
        "X_dim = train_loader.dataset[0][0].shape\n",
        "modelE= Encoder(X_dim, latent_dim).to(device)\n",
        "modelD = Decoder(X_dim, latent_dim).to(device)\n",
        "modelE, modelD = train(train_loader, modelE, modelD, latent_dim, lr=5e-3, max_epochs=2)\n",
        "\n",
        "print(\"Creating 10x10 grid of samples...\")\n",
        "N = 10\n",
        "# Plot standard normal Gaussian z\n",
        "z = pt.randn((N*N, latent_dim)).to(next(modelD.parameters()).device)\n",
        "\n",
        "with pt.set_grad_enabled(False):\n",
        "    X_pred = modelD(z)[0].cpu()\n",
        "\n",
        "save_image(((X_pred+1)/2), \"Outputs/VAE_samples.png\", nrow=N)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RzDoASssdBcD",
      "metadata": {
        "id": "RzDoASssdBcD"
      },
      "outputs": [],
      "source": [
        "rbfNN = trainRBF(modelE, modelD, train_loader, latent_dim, X_dim, k=4*latent_dim, zeta=1e-2, curveMetric=1, max_epochs=50, batch_size=train_loader.batch_size)\n",
        "# Set the better estimate in the decoder\n",
        "modelD.rbfNN = rbfNN\n",
        "modelD.improved_variance = True\n",
        "\n",
        "pt.save(modelD.state_dict(), \"TrainedModels/trainedVAE_D.pth\")\n",
        "\n",
        "return modelE, modelD\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9980f6af",
      "metadata": {
        "id": "9980f6af"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Computing metric tensor and metric derivative at points in latent space. Also\n",
        "# includes computations that require the induced metric (e.g. curve length).\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "import torch as pt\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "\n",
        "class InducedMetric:\n",
        "    \"\"\"\n",
        "    Class combining the functionality for the metric tensor.\n",
        "    \"\"\"\n",
        "    def __init__(self, modelG, X_dim, latent_dim, featureMapping=None):\n",
        "        self.modelG = modelG\n",
        "        self.modelG.eval()\n",
        "        self.device = next(modelG.parameters()).device\n",
        "        self.featureMapping = featureMapping\n",
        "\n",
        "        self.X_dim = X_dim\n",
        "        # Input_dim is the scalar dimension of the input, i.e. all dims multiplied if input is multi-dimensional.\n",
        "        self.input_dim = X_dim\n",
        "        if not isinstance(self.X_dim, int) and len(self.X_dim) > 1:\n",
        "            self.input_dim = np.asarray(self.input_dim).prod()\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "\n",
        "    def curveLength (self, dt, curve_points, curve_derivatives=None, M_batch_size=4):\n",
        "        \"\"\"\n",
        "        For a discretized curve defined by N points we find the curve length. If analytic curve_derivatives can be computed, we use those, otherwise we use finite difference on the curve_points.\n",
        "\n",
        "        Arguments:\n",
        "            dt (float or np.ndarray) : Time difference. Scalar if the t are\n",
        "                uniformly distributed, otherwise vector of time differences (should have one padded value such that shape is [N])\n",
        "            curve_points (np.ndarray) : Shape (N, d) where d is the coordinate\n",
        "                dimension of the curve.\n",
        "            curve_derivatives (np.ndarray) : Shape (N, d) containing the\n",
        "                derivatives of the curve at each point.\n",
        "\n",
        "        Returns:\n",
        "            Scalar value representing the length. No gradients enabled by default.\n",
        "        \"\"\"\n",
        "        N, d = curve_points.shape\n",
        "\n",
        "        if curve_derivatives is None:\n",
        "            z_upper = curve_points[1:]\n",
        "            z_lower = curve_points[:-1]\n",
        "            z_diff = z_upper - z_lower\n",
        "            M = self.M_valueAt(pt.Tensor((z_upper + z_lower)/2).to(self.device), M_batch_size=M_batch_size)\n",
        "\n",
        "            length = np.sqrt(np.matmul(np.matmul(z_diff.reshape(N-1, 1, d), M), z_diff.reshape(N-1, d, 1)).reshape(-1) + 1e-6).sum()\n",
        "\n",
        "        else:\n",
        "            M = self.M_valueAt(pt.Tensor(curve_points).to(self.device), M_batch_size=M_batch_size)\n",
        "            length = dt * np.sqrt(np.matmul(np.matmul(curve_derivatives.reshape(N, 1, d), M), curve_derivatives.reshape(N, d, 1)).reshape(-1) + 1e-6).sum()\n",
        "\n",
        "        return length\n",
        "\n",
        "\n",
        "    def curve_measure (self, curve_points, curve_derivatives, M_batch_size=4):\n",
        "        \"\"\"\n",
        "        Computes a measure to describe how much a curve follows the minimal eigenvectors of the induced metric tensor. Can show the improvement that is possible for a certain curve.\n",
        "        \"\"\"\n",
        "        N = curve_points.shape[0]\n",
        "        M = self.M_valueAt(pt.Tensor(curve_points).to(self.device), M_batch_size)\n",
        "        derivative_norm = np.sqrt(np.sum(curve_derivatives**2, axis=-1, keepdims=True))\n",
        "\n",
        "        eig, eigv = np.linalg.eig(M)\n",
        "        eigS = np.min(eig, axis=-1)\n",
        "        eigL = np.max(eig, axis=-1)\n",
        "        eigSIdx = np.argmin(eig, axis=-1)\n",
        "        # Shape of eigv is [N, d, d] where the COLUMNS of the [d,d] matrix are the eigenvectors of the corresponding eigenvalue.\n",
        "        eigvS = np.take_along_axis(eigv, eigSIdx.reshape(-1,1,1), axis=-1).reshape(N,-1)\n",
        "\n",
        "        condition_number = (eigL/eigS).reshape(N)\n",
        "        scalar_prod = np.einsum('ij, ij -> i', curve_derivatives/(derivative_norm+1e-6), eigvS)\n",
        "        # Would normally multiply with dt, but cancels out with normalization\n",
        "        measure = np.sum(condition_number*abs(scalar_prod))\n",
        "        normalized_measure = measure / np.sum(condition_number)\n",
        "\n",
        "        return normalized_measure\n",
        "\n",
        "\n",
        "    def M_valueAt(self, z, M_batch_size=None):\n",
        "        \"\"\"\n",
        "        Computes the M = J.T * J value at a certain position in the latent space z.\n",
        "\n",
        "        Arguments:\n",
        "            z (torch.Tensor) : position in latent space. Shape [N, d]\n",
        "            M_batch_size (int) : as computing the Jacobian and Hessian are very memory intensive, we may wish to use small batches instead. But this can only be used when no gradients are required!\n",
        "\n",
        "        Returns:\n",
        "            M (torch.Tensor or np.ndarray) : M matrix at z. Shape [N, d, d]. Numpy output when we use M_batch_size.\n",
        "        \"\"\"\n",
        "        N = 1 if len(z.shape)==1 else z.shape[0]\n",
        "        z = z.view(N, -1)\n",
        "\n",
        "        if M_batch_size is not None:\n",
        "            ### Loop over ourselves in batches. Detach every output and move to CPU.\n",
        "            M_values = []\n",
        "            for batch in range(0, N, M_batch_size):\n",
        "                M_values.append(\n",
        "                    self.M_valueAt(\n",
        "                        z[batch: batch+M_batch_size]\n",
        "                    ).detach().cpu().numpy()\n",
        "                )\n",
        "                gc.collect()\n",
        "            # Could output torch Tensor here, but NumPy will prevent confusion (torch Tensor with no gradients and different device)\n",
        "            return np.concatenate(M_values, axis=0)\n",
        "\n",
        "        z_J = z.repeat_interleave(self.input_dim, dim=0)\n",
        "        z_J.requires_grad_(True)\n",
        "\n",
        "        X_pred = self.modelG(z_J)\n",
        "        X_var = None\n",
        "        # For stochastic decoder\n",
        "        if isinstance(X_pred, tuple):\n",
        "            X_pred, X_var = X_pred\n",
        "\n",
        "        ### Feature Mapping\n",
        "        # Default is identity matrix mapping to output space\n",
        "        #M_fx = pt.eye(self.input_dim).view(1,self.input_dim, self.input_dim).repeat(N, 1, 1)\n",
        "        M_fx = None\n",
        "        if self.featureMapping is not None:\n",
        "            x_J = self.modelG(z)\n",
        "            if isinstance(x_J, tuple):\n",
        "                # For feature mapping to new output space we just consider mean of stochastic decoder\n",
        "                x_J = x_J[0]\n",
        "\n",
        "            x_J = x_J.view(-1, self.input_dim).detach().repeat_interleave(self.featureMapping.out_dim, dim=0)\n",
        "            x_J.requires_grad_(True)\n",
        "\n",
        "            feature_out = self.featureMapping(x_J)\n",
        "            grad_outputs = pt.eye(self.featureMapping.out_dim).repeat(N,1).to(self.device)\n",
        "\n",
        "            J_fx = pt.autograd.grad(outputs=feature_out, inputs=x_J,\n",
        "                grad_outputs=grad_outputs, create_graph=True, retain_graph=True,\n",
        "                only_inputs=True)[0].reshape(N, self.featureMapping.out_dim, self.input_dim)\n",
        "\n",
        "            M_fx = pt.matmul(pt.transpose(J_fx, 1, 2), J_fx)\n",
        "\n",
        "\n",
        "        # Generate gradients\n",
        "        grad_outputs = pt.eye(self.input_dim).repeat(N,1).to(self.device)\n",
        "        J = pt.autograd.grad(outputs=X_pred.view(-1, self.input_dim), inputs=z_J,\n",
        "            grad_outputs=grad_outputs, create_graph=True, retain_graph=True,\n",
        "            only_inputs=True)[0].reshape(N, self.input_dim, self.latent_dim)\n",
        "\n",
        "        if M_fx is None:\n",
        "            M = pt.matmul(pt.transpose(J, 1, 2), J)\n",
        "        else:\n",
        "            M = pt.matmul(pt.transpose(J, 1, 2), pt.matmul(M_fx, J))\n",
        "\n",
        "\n",
        "        ### For stochastic decoder\n",
        "        if X_var is not None:\n",
        "            X_std = pt.sqrt(X_var)\n",
        "            J_std = pt.autograd.grad(outputs=X_std.view(-1, self.input_dim), inputs=z_J,\n",
        "                    grad_outputs=grad_outputs, create_graph=True, retain_graph=True,\n",
        "                    only_inputs=True, allow_unused=True)[0]\n",
        "\n",
        "            if J_std is None:\n",
        "                # Constant variance, i.e. not important to consider\n",
        "                J_std = pt.zeros(N, self.input_dim, self.latent_dim)\n",
        "            else:\n",
        "                J_std = J_std.reshape(N, self.input_dim, self.latent_dim)\n",
        "\n",
        "\n",
        "            if M_fx is None:\n",
        "                M += pt.matmul(pt.transpose(J_std, 1, 2), J_std)\n",
        "            else:\n",
        "                M += pt.matmul(pt.transpose(J_std, 1, 2), pt.diagonal(M_fx, dim1=-2, dim2=-1).view(N, self.input_dim, 1) * J_std)\n",
        "\n",
        "\n",
        "        # Prevent singular M matrices\n",
        "        eps = 1e-6\n",
        "        return M + eps*pt.eye(self.latent_dim).to(self.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a1e888a",
      "metadata": {
        "id": "3a1e888a"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Bezier and Bspline curve definitions, including a trainable curve with\n",
        "# variable parameters.\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "import torch as pt\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "from scipy.special import binom\n",
        "from scipy.integrate import solve_bvp\n",
        "\n",
        "import warnings\n",
        "\n",
        "\n",
        "def BezierCurve (control_points):\n",
        "    \"\"\"\n",
        "    Creates a Bezier curve using all control points provided. Curve has the dimension of the input control_points.\n",
        "\n",
        "    Arguments:\n",
        "        control_points (torch.Tensor) [n, d] : n points to use for the curve, first element\n",
        "        should be start point and last element the end point.\n",
        "\n",
        "    Returns:\n",
        "        Python function taking t in [0,1] and returning a value on the curve [b, D] for batch size b.\n",
        "        Python function returning the derivative at each point too.\n",
        "        -- Not anymore needed // Python function for second derivative. Second derivative always exists if n>1 (which is the case for our endpoint interpolation).\n",
        "    \"\"\"\n",
        "    def bernstein (i, n):\n",
        "        binomial = binom(n, i.cpu()).to(i.device)\n",
        "        # If i has shape [n] and t has shape [b], result is [b, n]\n",
        "        return (lambda t: binomial * t**i * (1-t)**(n-i))\n",
        "\n",
        "    # Curve of order n has points P0 ... Pn, i.e. n+1 total points\n",
        "    n = control_points.shape[0]-1\n",
        "\n",
        "    b_0n = bernstein(pt.linspace(0, n, n+1).to(control_points.device), n)\n",
        "    # Cannot be done using b_0n as case where t=1 would have divide by zeros. otherwise 0**0 is handled correctly.\n",
        "    b_0n_1 = bernstein(pt.linspace(0, n-1, n).to(control_points.device), n-1)\n",
        "    #b_0n_2 = bernstein(torch.linspace(0, n-2, n-1).to(control_points.device), n-2)\n",
        "\n",
        "    # If computation too inefficient, could consider implementing explicit formula for Bezier.\n",
        "    def curve(t):\n",
        "        if isinstance(t, pt.Tensor):\n",
        "            t = t.view(-1, 1)\n",
        "\n",
        "        return (\n",
        "            pt.matmul(b_0n(t), control_points),\n",
        "            n * pt.matmul(b_0n_1(t), control_points[1:] - control_points[:-1]),\n",
        "            # n * (n-1) * torch.matmul(b_0n_2(t), control_points[2:] - 2*control_points[1:-1] + control_points[:-2])\n",
        "        )\n",
        "\n",
        "    return curve\n",
        "\n",
        "\n",
        "def CubicBSpline (control_points, knot_vector=None):\n",
        "    \"\"\"\n",
        "    Creates a Cubic B-spline using all control points provided. Order 4 B-spline. Requires at least 4 control points!\n",
        "\n",
        "    Arguments:\n",
        "        control_points (torch.Tensor) [n, d] : n control points to use for the curve, first element\n",
        "        should be start point and last element the end point.\n",
        "\n",
        "    Returns:\n",
        "        Python function taking t in [0,1] and returning a value on the curve [b, D] for batch size b.\n",
        "        Python function returning the derivative at each point too.\n",
        "        Python function for second derivative. Second derivative always exists if n>1 (which is the case for our endpoint interpolation).\n",
        "    \"\"\"\n",
        "    device = control_points.device\n",
        "    num_control = control_points.shape[0]\n",
        "    order = 4\n",
        "    if num_control < order:\n",
        "        assert False, \"Not enough control points for cubic Bspline!\"\n",
        "\n",
        "    if knot_vector is None:\n",
        "        # Cardinal Bspline if no knot vector is given.\n",
        "        knot_vector = pt.Tensor(np.concatenate([[0]*3, np.linspace(0, 1, num_control-2), [1]*3]).reshape(1, -1)).to(device)\n",
        "        # Total length of knot vector is (n+k). We want shape [1,n] such that subtraction will work later on.\n",
        "    else:\n",
        "        # Make sure it's a tensor on the right device and has the correct shape.\n",
        "        knot_vector = pt.as_tensor(knot_vector).view(1, -1).to(device)\n",
        "\n",
        "    def basis_func (knots, k, t):\n",
        "        \"\"\"\n",
        "        Returns the basis function at control point i and of degree k and evaluated at t, a torch Tensor of shape [N,1].\n",
        "        If this method is too slow, I can write down the whole formula for cubic Bsplines explicitly and implement it that way.\n",
        "\n",
        "        Arguments:\n",
        "            knots (torch.Tensor [1, n])\n",
        "            k (int)\n",
        "            t (torch.Tensor [N, 1])\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor [N, n]: the Bspline evaluated at given points for all knots\n",
        "            torch.Tensor [N, n-1]: derivative of Bspline at given points for all knots\n",
        "        \"\"\"\n",
        "        # Shape of knots is n+k, so n (active knots) is knots.shape - k\n",
        "        n = knots.shape[1] - k\n",
        "\n",
        "        if k == 1:\n",
        "            return pt.where(pt.logical_and(t >= knots[:, :-1], t <= knots[:, 1:]),\n",
        "                            pt.ones([t.shape[0], n]).to(device),\n",
        "                            pt.zeros([t.shape[0], n]).to(device)\n",
        "                        )\n",
        "        else:\n",
        "            # Such that total new knot_vector length is still n+k\n",
        "            B_ik_1 = basis_func(knots[:, :-1], k-1, t)\n",
        "            B_i1k_1 = basis_func(knots[:, 1:], k-1, t)\n",
        "\n",
        "            # t - knots[:n] is a shape [N, n] matrix\n",
        "            term1 = pt.where(knots[:, k-1:-1] - knots[:, :n] != 0,\n",
        "                                B_ik_1 * (t - knots[:, :n]) / (knots[:, k-1:-1] - knots[:, :n]),\n",
        "                                pt.zeros_like(B_ik_1))\n",
        "            term2 = pt.where(knots[:, k:] - knots[:, 1:n+1] != 0,\n",
        "                                    B_i1k_1 * (knots[:, k:] - t) / (knots[:, k:] - knots[:, 1:n+1]),\n",
        "                                pt.zeros_like(B_i1k_1))\n",
        "\n",
        "            res = term1+term2\n",
        "            if knots.shape[1] == num_control+order:\n",
        "                # We're in the highest loop\n",
        "                return res, B_i1k_1[:,:-1]\n",
        "\n",
        "            return res\n",
        "\n",
        "\n",
        "    def curve(t):\n",
        "        if not isinstance(t, pt.Tensor):\n",
        "            t = pt.as_tensor(t)\n",
        "        t = t.view(-1, 1).to(device)\n",
        "\n",
        "        basis, dbasis = basis_func(knot_vector, order, t)\n",
        "        #dbasis = basis_func(knot_vector[:, 1:-1], order-1, t)\n",
        "        gamma = pt.matmul(basis, control_points)\n",
        "        dgamma = (order-1) * pt.matmul(\n",
        "            dbasis / (knot_vector[:, order:-1] - knot_vector[:, 1:num_control]),\n",
        "            (control_points[1:] - control_points[:-1])\n",
        "        )\n",
        "\n",
        "        return gamma, dgamma\n",
        "\n",
        "    return curve\n",
        "\n",
        "\n",
        "class trainableCurve (nn.Module):\n",
        "    def __init__(self, start, end, max_nodes=10, bspline=True):\n",
        "        \"\"\"\n",
        "        BSpline: Adding nodes to the curve happen in a binary fashion, we always add 2^n nodes such that knots stay the same, and we simply refine the curve by adding more points in between the previous knots.\n",
        "\n",
        "        Arguments:\n",
        "            max_nodes (int) : all node parameters are created at the start (such that\n",
        "                              they are trainable parameters of the module). Counts all nodes in between start and end (excluding both). For BSplines, it's bes that max_nodes is 2^n - 1, wastes no memory in that way.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # There is one UserWarning thrown for instantiating ParameterLists. Should be fixed by PyTorch soon?\n",
        "        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "        self.start = nn.Parameter(start, requires_grad=False)\n",
        "        self.end = nn.Parameter(end, requires_grad=False)\n",
        "        self.bspline = bspline\n",
        "\n",
        "        # Without ParameterList the entries within a Parameter are not moved to device.\n",
        "        # Initialize first 2 points on a straight line, rest will be set later\n",
        "        self.new_nodes = nn.ParameterList([nn.Parameter(self.start + (i+1)/3 * (self.end - self.start)) for i in range(max_nodes)])\n",
        "\n",
        "        # Keep as list such that moving to device and adding nodes work as expected.\n",
        "        # CubicBsplines require 2 new nodes, whereas Bezier can start with 1 node.\n",
        "        self.points = [self.start, self.new_nodes[0], self.new_nodes[1], self.end]\n",
        "        self.nodecount = 2\n",
        "        self.knot_vector = [0,0,0,0,1,1,1,1]\n",
        "\n",
        "    def add_node(self):\n",
        "        if (self.nodecount >= len(self.new_nodes)):\n",
        "            assert False, \"Not enough max_nodes to use for another node addition!\"\n",
        "\n",
        "        ### For Bezier -----------\n",
        "        if not self.bspline:\n",
        "            self.points = self.points[:-1] + [self.new_nodes[self.nodecount], self.end]\n",
        "            self.nodecount += 1\n",
        "        ### ----------------------\n",
        "\n",
        "        ### For Bspline ----------\n",
        "        else:\n",
        "            # We change 4 control_points into 5 control_points on the knot interval that is largest (we halve it).\n",
        "            # Find largest knot interval:\n",
        "            k = np.argmax(np.array(self.knot_vector)[1:] - np.array(self.knot_vector)[:-1])\n",
        "            new_knot = (self.knot_vector[k+1]+self.knot_vector[k])/2\n",
        "            # Degree 3 curve\n",
        "            p = 3\n",
        "\n",
        "            # First we add the new control point\n",
        "            if self.knot_vector[k+p] - self.knot_vector[k] == 0:\n",
        "                import pdb; pdb.set_trace()\n",
        "            with pt.set_grad_enabled(False):\n",
        "                ratio = (new_knot - self.knot_vector[k]) / (self.knot_vector[k+p] - self.knot_vector[k])\n",
        "                self.new_nodes[self.nodecount] *= 0\n",
        "                self.new_nodes[self.nodecount] += (1-ratio)*self.points[k-1] + ratio*self.points[k]\n",
        "\n",
        "                # We update the points from back to front in-place.\n",
        "                for i in range(k-1, k-p, -1):\n",
        "                    if self.knot_vector[i+p] - self.knot_vector[i] == 0:\n",
        "                        import pdb; pdb.set_trace()\n",
        "                    ratio = (new_knot - self.knot_vector[i]) / (self.knot_vector[i+p] - self.knot_vector[i])\n",
        "                    self.points[i] *= ratio\n",
        "                    self.points[i] += (1-ratio)*self.points[i-1]\n",
        "\n",
        "            self.points.insert(k, self.new_nodes[self.nodecount])\n",
        "            self.knot_vector.insert(k+1, new_knot)\n",
        "            self.nodecount += 1\n",
        "        ### ----------------------\n",
        "\n",
        "\n",
        "    def forward(self, t):\n",
        "        if not self.bspline:\n",
        "            return BezierCurve(pt.stack(self.points))(t)\n",
        "        else:\n",
        "            return CubicBSpline(pt.stack(self.points), self.knot_vector)(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "029c0951",
      "metadata": {
        "id": "029c0951"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Training shorter curves than straight line.\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "import torch as pt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "import sys\n",
        "sys.path.append('./')\n",
        "\n",
        "\n",
        "def trainGeodesic (bc0, bc1, N, metricSpace, M_batch_size=4, max_epochs=1000, val_epoch=10, verbose=2):\n",
        "    \"\"\"\n",
        "    Finds a shorter curve from bc0 to bc1 (attention, this may not be symmetric) in the metricSpace.\n",
        "\n",
        "    Arguments:\n",
        "        bc0 (torch.Tensor [latent_dim]) : starting point for interpolation.\n",
        "        bc1 (torch.Tensor [latent_dim]) : end point of interpolation.\n",
        "        N (int) : discretization of shorter curve.\n",
        "        metricSpace (Geometry.metric.InducedMetric) : contains generator model\n",
        "            with jacobian computation.\n",
        "        M_batch_size (int) : batchsize for computation of metric.\n",
        "        val_epoch (int) : Defines when the curve is reset to optimal.\n",
        "        verbose (int) : 0 is no plots nor prints, 1 is no plots but print outputs, 2 is both.\n",
        "\n",
        "    Returns:\n",
        "        best_gamma (func: [b, 1] -> [b, latent_dim]) : curve function mapping\n",
        "            scalar parameter to vector points in latent space.\n",
        "        length_history (list) : list of lengths during training of shorter curve.\n",
        "    \"\"\"\n",
        "    ### Parameters for training\n",
        "    lr_init = 1e0\n",
        "    lr_gamma = 0.9\n",
        "    max_nodecount = 10\n",
        "    max_hardschedules = 5\n",
        "    hardschedule_factor = 0.3\n",
        "\n",
        "    # Have a validation set of points to use for validation. Let's use half of N while training.\n",
        "    t_val = pt.linspace(0, 1, N)\n",
        "\n",
        "    gamma = trainableCurve(bc0, bc1, max_nodes=max_nodecount)\n",
        "    gamma.to(metricSpace.device)\n",
        "\n",
        "    # Start with straight line\n",
        "    best_gamma = copy.deepcopy(gamma)\n",
        "    with pt.set_grad_enabled(False):\n",
        "        res, diff = best_gamma(t_val.to(metricSpace.device))\n",
        "        g = res.detach().cpu().numpy()\n",
        "        dg = diff.detach().cpu().numpy()\n",
        "\n",
        "    dt = t_val[1] - t_val[0]\n",
        "    best_length = metricSpace.curveLength(dt, g, dg, M_batch_size=M_batch_size)\n",
        "    straight_measure = metricSpace.curve_measure(g, dg, M_batch_size=M_batch_size)\n",
        "\n",
        "    # Let tolerance depend on the length of straight line.\n",
        "    length_tol = best_length/200.\n",
        "\n",
        "    print(f\"Straight curve length: {best_length:.3f}\")\n",
        "    print(f\"Straight curve measure: {straight_measure:.3f}\")\n",
        "\n",
        "    optimizer = pt.optim.Adam(gamma.parameters(), lr=lr_init, weight_decay=1e-4)\n",
        "\n",
        "    # Multiplies the given lr with lambda every call to the scheduler\n",
        "    scheduler = pt.optim.lr_scheduler.MultiplicativeLR(optimizer, lambda epoch: lr_gamma)\n",
        "\n",
        "    hardSchedules = 0\n",
        "    length_history = [best_length]\n",
        "    for epoch in range(max_epochs):\n",
        "        if (epoch+1) % val_epoch:\n",
        "            # Training: best_gamma unchanged\n",
        "            runGammaEpoch(gamma, optimizer, scheduler, t_val, metricSpace, M_batch_size=M_batch_size, train=True)\n",
        "        else:\n",
        "            # Validation\n",
        "            length = runGammaEpoch(gamma, None, None, t_val, metricSpace, M_batch_size=M_batch_size, train=False)\n",
        "            length_history.append(length)\n",
        "\n",
        "            if verbose >= 1:\n",
        "                print('-'*10)\n",
        "                print(f\"Learning rate: {optimizer.param_groups[0]['lr']:.5e}\")\n",
        "                print(f\"Epoch[{epoch+1:04d}/{max_epochs}]: Length: {length:.3f}\")\n",
        "\n",
        "            length_improvement = best_length - length\n",
        "            if length < best_length:\n",
        "                # Store current best network for minimal length\n",
        "                if verbose >= 1:\n",
        "                    print(\"Found better curve!\")\n",
        "                best_gamma = copy.deepcopy(gamma)\n",
        "                best_length = length\n",
        "\n",
        "            if length_improvement < length_tol:\n",
        "                # In case the loss increases, we first wanna rapidly decrease lr before we add nodes.\n",
        "                # We restart from the best solution when adding nodes or decreasing LR\n",
        "                if hardSchedules >= max_hardschedules:\n",
        "                    ### New Node\n",
        "                    if (best_gamma.nodecount >= max_nodecount):\n",
        "                        print(\"Node limit reached!\")\n",
        "                        break\n",
        "                    if verbose >= 1:\n",
        "                        print(\"*** Adding node ***\")\n",
        "                    best_gamma.add_node()\n",
        "\n",
        "                ### Set gamma, and Reset best_gamma so it isn't trained\n",
        "                gamma = best_gamma\n",
        "                best_gamma = copy.deepcopy(best_gamma)\n",
        "\n",
        "                # Re-initialize the optimizer to only the gamma parameters with gradients\n",
        "                optimizer = pt.optim.Adam(filter(lambda p: p.requires_grad, gamma.parameters()), lr=lr_init, weight_decay=1e-4)\n",
        "                scheduler = pt.optim.lr_scheduler.MultiplicativeLR(optimizer, lambda epoch: lr_gamma)\n",
        "\n",
        "                if hardSchedules < max_hardschedules:\n",
        "                    if verbose >= 1:\n",
        "                        print(\"* Decreasing LR *\")\n",
        "                    hardSchedules += 1\n",
        "                    optimizer.param_groups[0]['lr'] *= hardschedule_factor**hardSchedules\n",
        "                else:\n",
        "                    # Reset hardSchedules when adding new node\n",
        "                    hardSchedules = 0\n",
        "\n",
        "\n",
        "    with pt.set_grad_enabled(False):\n",
        "        res, diff = best_gamma(t_val.to(metricSpace.device))\n",
        "\n",
        "    curve_measure = metricSpace.curve_measure(res.detach().cpu().numpy(), diff.detach().cpu().numpy(), M_batch_size=M_batch_size)\n",
        "    del res, diff\n",
        "\n",
        "    print(f\"New curve length: {best_length:.3f}\")\n",
        "    print(f\"New curve measure: {curve_measure:.3f}\")\n",
        "\n",
        "    return best_gamma, length_history\n",
        "\n",
        "\n",
        "def runGammaEpoch(gamma, optimizer, scheduler, t_val, metricSpace, M_batch_size=4, train=True):\n",
        "    \"\"\"\n",
        "    During validation we do not perturb the curve parameter.\n",
        "    \"\"\"\n",
        "    eps = 1e-6\n",
        "    dt = (t_val[1] - t_val[0]).to(metricSpace.device)\n",
        "    t = t_val.to(metricSpace.device)\n",
        "\n",
        "    if train:\n",
        "        gamma.train()\n",
        "\n",
        "        # Slightly perturb all the t values, such that it isn't sampled at the same points every time.\n",
        "        perturb = pt.normal(pt.zeros_like(t), 0.1*dt).to(metricSpace.device)\n",
        "        t = pt.min(pt.max(t+perturb, 0*t), 0*t+1)\n",
        "    else:\n",
        "        gamma.eval()\n",
        "\n",
        "    length = 0\n",
        "    gamma.zero_grad()\n",
        "    for batch in range(0, t_val.shape[0], M_batch_size):\n",
        "        # Grad necessary during validation as well for M computation\n",
        "        with pt.set_grad_enabled(True):\n",
        "            res_batch, diff_batch = gamma(t[batch:batch+M_batch_size])\n",
        "            N = res_batch.shape[0]\n",
        "            M = metricSpace.M_valueAt(res_batch)\n",
        "            # Length minimized\n",
        "            norm = pt.matmul(pt.matmul(diff_batch.view(N, 1, -1), M), diff_batch.view(N, -1, 1)).view(-1)\n",
        "\n",
        "            loss = (dt**2) * norm.sum()\n",
        "            length += dt * pt.sqrt(norm.detach().cpu()+eps).sum()\n",
        "            # When we don't backward during evaluation too, M clogs up the GPU memory.\n",
        "            loss.backward()\n",
        "\n",
        "    if train:\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    return length.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "560f29ab",
      "metadata": {
        "id": "560f29ab"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Methods for evaluating generative models.\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "import math\n",
        "import torch as pt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def create_sequence (model, straight_plot, curve_plot, seq_length=None):\n",
        "    \"\"\"\n",
        "    Compares straight line vs shorter curve side by side. Rounds towards seq_length, round down. So if we wanted 10 sequence length, but our curves had 14 points, then we get 7 in the end (14/10 = 1.4 -> rounded up 2, stepsize 2 [0:14:2]).\n",
        "\n",
        "    Arguments:\n",
        "        model (nn.Module) : generative model creating images from latent vectors.\n",
        "        straight_plot (np.ndarray [N, latent_dim]) : array of points on a\n",
        "            straight line in latent space.\n",
        "        curve_plot (np.ndarray [N, latent_dim]) : array of points on a\n",
        "            shorter curve in latent space.\n",
        "        seq_length (int) : length of image sequence to create, if None then it's\n",
        "            the length of straight_plot/curve_plot.\n",
        "\n",
        "    Returns:\n",
        "        None, creates a figure and stores it at \"Outputs/interpolation_sequence.png\".\n",
        "    \"\"\"\n",
        "    print(\"Creating interpolation sequence...\")\n",
        "\n",
        "    if seq_length is not None:\n",
        "        N = straight_plot.shape[0]\n",
        "        straight_plot = straight_plot[::math.ceil(N/seq_length)]\n",
        "        curve_plot = curve_plot[::math.ceil(N/seq_length)]\n",
        "\n",
        "    seq_length = straight_plot.shape[0]\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # figsize is W x H\n",
        "    fig = plt.figure(figsize=(seq_length, 2))\n",
        "\n",
        "    for point_num in range(seq_length):\n",
        "        ax0 = plt.subplot2grid((2, seq_length), (0, point_num))\n",
        "        ax0.axis('off')\n",
        "        ax1 = plt.subplot2grid((2, seq_length), (1, point_num))\n",
        "        ax1.axis('off')\n",
        "        if point_num == seq_length-1:\n",
        "            ax0.text(30, 13, \"Straight Curve\", fontsize=9)\n",
        "            ax1.text(30, 13, \"Shorter Curve\", fontsize=9)\n",
        "\n",
        "        curve_point = curve_plot[point_num]\n",
        "        straight_point = straight_plot[point_num]\n",
        "\n",
        "        with pt.set_grad_enabled(False):\n",
        "            out_straight = model(pt.Tensor(straight_point).to(device).view(1,-1))\n",
        "            if isinstance(out_straight, tuple):\n",
        "                out_straight = out_straight[0]\n",
        "            out_straight = out_straight.detach().squeeze().cpu().numpy()\n",
        "\n",
        "            out_curve = model(pt.Tensor(curve_point).to(device).view(1,-1))\n",
        "            if isinstance(out_curve, tuple):\n",
        "                out_curve = out_curve[0]\n",
        "            out_curve = out_curve.detach().squeeze().cpu().numpy()\n",
        "\n",
        "        ax0.imshow(out_straight, cmap='gray')\n",
        "        ax1.imshow(out_curve, cmap='gray')\n",
        "\n",
        "    fig.savefig(\"Outputs/interpolation_sequence.png\", bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def create_crosscorrelation (model, straight_plot, curve_plot, featureMapping=None):\n",
        "    \"\"\"\n",
        "    Cross correlation of outputs from both curves. Currently implemented as elementwise dot product between images.\n",
        "\n",
        "    Arguments:\n",
        "        model (nn.Module) : generative model creating images from latent vectors.\n",
        "        straight_plot (np.ndarray [N, latent_dim]) : array of points on a\n",
        "            straight line in latent space.\n",
        "        curve_plot (np.ndarray [N, latent_dim]) : array of points on a\n",
        "            shorter curve in latent space.\n",
        "\n",
        "    Returns:\n",
        "        None, creates a figure and stores it at \"Outputs/cross_correlation.png\".\n",
        "    \"\"\"\n",
        "    print(\"Creating cross-correlation...\")\n",
        "    device = next(model.parameters()).device\n",
        "    N = straight_plot.shape[0]\n",
        "\n",
        "    # figsize is W x H\n",
        "    curve_list = []\n",
        "    straight_list = []\n",
        "    for point_num in range(N):\n",
        "        curve_point = curve_plot[point_num]\n",
        "        straight_point = straight_plot[point_num]\n",
        "\n",
        "        with pt.set_grad_enabled(False):\n",
        "            out_curve = model(pt.Tensor(curve_point).to(device).view(1,-1))\n",
        "            out_straight = model(pt.Tensor(straight_point).to(device).view(1,-1))\n",
        "\n",
        "            if isinstance(out_straight, tuple):\n",
        "                out_curve = out_curve[0]\n",
        "                out_straight = out_straight[0]\n",
        "\n",
        "            if featureMapping is not None:\n",
        "                out_curve = featureMapping(out_curve)\n",
        "                out_straight = featureMapping(out_straight)\n",
        "\n",
        "            out_curve = out_curve.detach().squeeze().cpu().numpy().reshape(-1)\n",
        "            out_straight = out_straight.detach().squeeze().cpu().numpy().reshape(-1)\n",
        "\n",
        "        curve_list.append(out_curve)\n",
        "        straight_list.append(out_straight)\n",
        "\n",
        "    # Maybe we wanna convolve the whole lists\n",
        "    curve_vec = np.stack(curve_list, axis=0)\n",
        "    straight_vec = np.stack(straight_list, axis=0)\n",
        "    # Normalize\n",
        "    curve_vec /= np.linalg.norm(curve_vec, axis=1, keepdims=True)\n",
        "    straight_vec /= np.linalg.norm(straight_vec, axis=1, keepdims=True)\n",
        "    curve_corr = np.dot(curve_vec, np.transpose(curve_vec))\n",
        "    straight_corr = np.dot(straight_vec, np.transpose(straight_vec))\n",
        "    #signal.convolve2d(out_curve.reshape(28,28), out_straight.reshape(28,28))\n",
        "\n",
        "    ### Plotting\n",
        "    fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(6, 12))\n",
        "    vmin = min(np.amin(curve_corr), np.amin(straight_corr))\n",
        "    vmax = max(np.amax(curve_corr), np.amax(straight_corr))\n",
        "    # Could stick to [0,1] so we can compare images with one another\n",
        "    levels = np.linspace(vmin, vmax, 15)\n",
        "\n",
        "    im0 = ax0.contourf(np.linspace(1,N,N), np.linspace(1,N,N), straight_corr, levels=levels, cmap='jet')\n",
        "    fig.colorbar(im0, ax=ax0)\n",
        "    ax0.set_title(\"Straight Curve\")\n",
        "\n",
        "    im1 = ax1.contourf(np.linspace(1,N,N), np.linspace(1,N,N), curve_corr, levels=levels, cmap='jet')\n",
        "    fig.colorbar(im1, ax=ax1)\n",
        "    ax1.set_title(\"Shorter Curve\")\n",
        "\n",
        "    fig.savefig(\"Outputs/cross_correlation.png\", bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "    ### Compute a measure based on cross-correlation\n",
        "    straight_var = np.var(straight_corr)\n",
        "    curve_var = np.var(curve_corr)\n",
        "    print(f\"Straight variance: {straight_var:.3f}\")\n",
        "    print(f\"Curve variance: {curve_var:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "698acde9",
      "metadata": {
        "id": "698acde9",
        "outputId": "4cc1eb76-a044-4c70-fb81-4f8591d61681",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Interpolation in latent space, by default for MNIST digits, but can be changed\n",
        "# easily.\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "import numpy as np\n",
        "import torch as pt\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "import sys\n",
        "sys.path.append('./')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if not os.path.exists(\"Outputs\"):\n",
        "    os.makedirs(\"Outputs\")\n",
        "\n",
        "device = pt.device('cuda') if pt.cuda.is_available() else pt.device('cpu')\n",
        "\n",
        "# Need to manually set bc anyways.\n",
        "X_dim = [1,28,28]\n",
        "\n",
        "# Discretization of geodesic curve\n",
        "N_t = 20\n",
        "#bc0 = -pt.ones(latent_dim)\n",
        "#bc1 = pt.ones(latent_dim)\n",
        "\n",
        "bc0,_ = modelE(pt.zeros((1, 1, 28, 28)).cuda())\n",
        "#bc0,_ = modelE(train_images[9].view(1,1,28,28).cuda())\n",
        "bc1,_ = modelE(train_images[9].view(1,1,28,28).cuda())\n",
        "bc0 = bc0.squeeze()\n",
        "bc1 = bc1.squeeze()\n",
        "\n",
        "epochs= 200\n",
        "\n",
        "M_batch_size = 1\n",
        "\n",
        "modelG = Decoder(X_dim, latent_dim)\n",
        "trained_gen = \"trainedVAE_D.pth\"\n",
        "\n",
        "modelG.load_state_dict(pt.load(os.path.join(\"TrainedModels\", trained_gen)))\n",
        "modelG.to(device)\n",
        "modelG.eval()\n",
        "print(\"Generator loaded!\")\n",
        "\n",
        "### Create metric space for curvelengths\n",
        "metricSpace = InducedMetric(modelG, X_dim, latent_dim)\n",
        "\n",
        "\n",
        "### Find shorter path than straight line\n",
        "print(\"Optimizing for shorter path...\")\n",
        "start = time.time()\n",
        "best_gamma, length_history = trainGeodesic(\n",
        "    bc0, bc1, N_t, metricSpace,\n",
        "    M_batch_size=M_batch_size,\n",
        "    max_epochs=epochs,\n",
        "    val_epoch=5\n",
        ")\n",
        "print(f\"Optimization took {time.time()-start:.1f}s.\")\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(12,9))\n",
        "ax1.plot(np.arange(len(length_history)-1), length_history[1:], linewidth=2)\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Length', color='blue')\n",
        "fig.savefig(\"Outputs/Length_History.png\", bbox_inches='tight')\n",
        "plt.close(fig)\n",
        "\n",
        "\n",
        "### Plot shorter curve\n",
        "t_plot = pt.linspace(0, 1, 2*N_t).to(device).view(-1,1)\n",
        "dt = 1 / (2*N_t - 1)\n",
        "\n",
        "with pt.set_grad_enabled(False):\n",
        "    straight_plot = BezierCurve(pt.stack([bc0, bc1]).to(device))(t_plot)[0].cpu().numpy()\n",
        "    curve_plot = best_gamma(t_plot)[0].detach().cpu().numpy()\n",
        "\n",
        "\n",
        "### Evaluate interpolation curves\n",
        "create_sequence(modelG, straight_plot, curve_plot, seq_length=20)\n",
        "create_crosscorrelation(modelG, straight_plot, curve_plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "112869ee",
      "metadata": {
        "id": "112869ee"
      },
      "outputs": [],
      "source": [
        "bc0,_ = modelE(pt.zeros((1, 1, 28, 28)).cuda())\n",
        "bc1,_ = modelE(train_images[1].view(1,1,28,28).cuda())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f1e09a7",
      "metadata": {
        "id": "6f1e09a7"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(dataloader)\n",
        "train_images, train_labels = next(dataiter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ca01ee6",
      "metadata": {
        "id": "9ca01ee6",
        "outputId": "fbab2121-0c97-4873-ddb5-52991aaff798"
      },
      "outputs": [],
      "source": [
        "import torchvision.utils as vutils\n",
        "\n",
        "plt.figure(figsize = (5,10))\n",
        "out = vutils.make_grid(train_images[0:10], normalize=True)\n",
        "plt.imshow(out.numpy().transpose((1, 2, 0)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
